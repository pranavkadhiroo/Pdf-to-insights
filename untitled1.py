# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZZaquk6jMbw8l0FBapEtkneeElURcEeT
"""


import streamlit as st
import fitz  # PyMuPDF
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
import tempfile
import os

# -----------------------------
# STEP 1: Extract text from PDF
# -----------------------------
def extract_text_from_pdf(uploaded_file):
    text = ""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_path = tmp_file.name
    doc = fitz.open(tmp_path)
    for page in doc:
        text += page.get_text()
    os.remove(tmp_path)
    return text

# -----------------------------
# STEP 2: Split into chunks
# -----------------------------
def split_text(text):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100
    )
    return splitter.split_text(text)

# -----------------------------
# STEP 3: Embed + Vector DB
# -----------------------------
def embed_chunks(chunks):
    embeddings = OpenAIEmbeddings()
    db = FAISS.from_texts(chunks, embeddings)
    return db

# -----------------------------
# STEP 4: Query with LLM
# -----------------------------
def query_pdf(db, query):
    docs = db.similarity_search(query)
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
    chain = load_qa_chain(llm, chain_type="stuff")
    return chain.run(input_documents=docs, question=query)

# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="ðŸ“„ PDF-to-Insights")
st.title("ðŸ“„ PDF-to-Insights Tool using GenAI")

uploaded_file = st.file_uploader("Upload your PDF", type="pdf")
query = st.text_input("Ask a question about the document:")

if uploaded_file:
    with st.spinner("Processing..."):
        text = extract_text_from_pdf(uploaded_file)
        chunks = split_text(text)
        db = embed_chunks(chunks)

    if query:
        with st.spinner("Querying..."):
            try:
                response = query_pdf(db, query)
                st.markdown("### ðŸ§  Answer")
                st.write(response)
            except Exception as e:
                st.error(f"Error during query: {e}")

